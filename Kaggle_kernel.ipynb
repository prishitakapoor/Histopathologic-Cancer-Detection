{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection\n",
    "\n",
    "### CSE4020-Machine Learning<br>Faculty: Dr. Syed Ibrahim<br>Slot: C1\n",
    "### By:&ensp;Prishita Kapoor-17EC035 <br>&emsp;&ensp;\n",
    "\n",
    "### Dataset Description\n",
    "In this dataset, we are provided with a large number of small pathology images to classify. Files are named with an image id. The train_labels.csv file provides the ground truth for the images in the train folder. We are predicting the labels for the images in the test folder. A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.\n",
    "\n",
    "### Methodology\n",
    "We have used Convolutional Neural Networks to approach this problem. A Convolutional Neural Network (ConvNet/CNN) is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. A ConvNet is able to successfully capture the Spatial and Temporal dependencies in an image through the application of relevant filters. The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Load the modules\n",
    "from glob import glob \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras,cv2,os\n",
    "from keras.callbacks import TensorBoard\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/train/f46f19fc90347d350431da5bfcf955d...</td>\n",
       "      <td>f46f19fc90347d350431da5bfcf955d9c1418b43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/train/330c56d7a3a1a808d711386c136b874...</td>\n",
       "      <td>330c56d7a3a1a808d711386c136b874a87081526</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/train/b7b8babd812d5edbad7dd9b155ee29f...</td>\n",
       "      <td>b7b8babd812d5edbad7dd9b155ee29fbede4ab81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  ...  label\n",
       "0  ../input/train/f46f19fc90347d350431da5bfcf955d...  ...      1\n",
       "1  ../input/train/330c56d7a3a1a808d711386c136b874...  ...      0\n",
       "2  ../input/train/b7b8babd812d5edbad7dd9b155ee29f...  ...      0\n",
       "\n",
       "[3 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../input/\"\n",
    "train_path = path + 'train/'\n",
    "test_path = path + 'test/'\n",
    "\n",
    "df = pd.DataFrame({'path': glob(os.path.join(train_path,'*.tif'))}) # load the filenames\n",
    "df['id'] = df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) # keep only the file names in 'id'\n",
    "labels = pd.read_csv(path+\"train_labels.csv\") # read the provided labels\n",
    "df = df.merge(labels, on = \"id\") # merge labels and filepaths\n",
    "df.head(3) # print the first three entrys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>A function **_load _ data_** is created to load the images as a numpy array.<br>\n",
    "We have used openCV to convert the image into matrix representation. \n",
    "The function cv2.imread() is used to read an image.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "bd41130d035a4f7e570cc6834cf91efcec07a25c"
   },
   "outputs": [],
   "source": [
    "def load_data(N,df):\n",
    "    # allocate a numpy array for the images (N, 96x96px, 3 channels, values 0 - 255)\n",
    "    X = np.zeros([N,96,96,3],dtype=np.uint8) \n",
    "    #convert the labels to a numpy array too\n",
    "    y = np.squeeze(df.as_matrix(columns=['label']))[0:N]\n",
    "    #read images one by one, tdqm notebook displays a progress bar\n",
    "    for i, row in tqdm_notebook(df.iterrows(), total=N):\n",
    "        if i == N:\n",
    "            break\n",
    "        X[i] = cv2.imread(row['path'])\n",
    "          \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>We have used **gc** to remove the dataframe stored in the RAM.<br>\n",
    "This is done to free up some RAM else we can get _Memory Error_ in systems having low RAM.<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4ce8344213e53df86d384a2e31e25b9cb6d5f839"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ce0915b42a418e829693f2f6d4b500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=220025), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook,trange\n",
    "N = df[\"path\"].size # get the number of images in the training data set\n",
    "0df=None\n",
    "gc.collect(); #garbage collector for memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "53bcfe6d74d1d95cd088e6eb85983f711da663b4"
   },
   "outputs": [],
   "source": [
    "#Importing necessary librares\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>We have split the train data into  **_80:20_**  in train and validation set. <br>\n",
    "Before spliiting the data, we have shuffled the data randomly to make sure that there is no bias in the data.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f541d9cc233dabd2afc83247c4a7141dfa24387c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "X_train, X_test = X[:train_pct_index], X[train_pct_index:]\n",
    "y_train, y_test = y[:train_pct_index], y[train_pct_index:]\n",
    "X=None\n",
    "gc.collect()\n",
    "y=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Defining the kernel size,pool size and the numbers of filter to be used in each layer<br>\n",
    "**kernel size:** Refers to the size of the convolutional filter<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8bab6c4c0224f7e5d0e842de2dc0a4bd8e49b82e"
   },
   "outputs": [],
   "source": [
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 64\n",
    "second_filters = 128\n",
    "third_filters = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout Rate\n",
    "In this we have defined the droupout rate fro convolution layer as well as dense layer<br>\n",
    "<br>\n",
    "Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass.\n",
    "<br><br>\n",
    "This in turn results in a network that is capable of better generalization and is **less likely to overfit the training data**.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a39c3cac0e03bb25abc5729955880a9023695258"
   },
   "outputs": [],
   "source": [
    "dropout_conv = 0.2 #dropout ratein convolution layer\n",
    "dropout_dense = 0.2 #dropout rate in dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model and adding layers to the model<br>\n",
    "**Conv2D:** This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs.<br><br>\n",
    "**Batch Normalization:** Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.<br>\n",
    "<br>\n",
    "**Activation:** Define the activation function for the Layer<br>\n",
    "<br>\n",
    "**MaxPool2D:** Max pooling operation for temporal data.This is to decrease the computational power required to process the data through dimensionality reduction. <br>\n",
    "<br>\n",
    "**Dropout:** Applies Dropout to the input.Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.<br>\n",
    "<br>\n",
    "**Flatten:** A flatten operation on a tensor reshapes the tensor to have a shape that is equal to the number of elements contained in the tensor. This is the same thing as a 1d-array of elements.<br>\n",
    "<br>\n",
    "**Dense:** A Dense layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer.A Dense(512) has 512 neurons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "ad0afaa178f5b7624d920c83f08066ace157f068"
   },
   "outputs": [],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "model = Sequential()\n",
    "\n",
    "#now add layers to it\n",
    "\n",
    "#conv block 1\n",
    "model.add(Conv2D(first_filters, kernel_size, input_shape = (96, 96, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(first_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#conv block 2\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(second_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#conv block 3\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(third_filters, kernel_size, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPool2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "#a fully connected (also called dense) layer at the end\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "\n",
    "#finally convert to values of 0 to 1 using the sigmoid activation function\n",
    "model.add(Dense(1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the Model\n",
    "\n",
    "The model is compiled with binary crossentropy as the loss function. The Optimizer used in the model is **_Adam_** with a learning rate of **_0.001_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "b603a2b2bb6715e350991ef741c2e93f72349e7a"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.binary_crossentropy,optimizer=keras.optimizers.Adam(0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "6f0d996de2272e13de5674aed08c27d54ace911b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 94, 94, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 94, 94, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 94, 94, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 92, 92, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 92, 92, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 92, 92, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 90, 90, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 90, 90, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 90, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 45, 45, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 43, 43, 128)       73728     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 43, 43, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 43, 43, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 41, 41, 128)       147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 41, 41, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 41, 41, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 39, 39, 128)       147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 39, 39, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 39, 39, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 19, 19, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 17, 17, 256)       294912    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 17, 17, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 15, 15, 256)       589824    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 15, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 256)       589824    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2359296   \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 4,284,673\n",
      "Trainable params: 4,281,473\n",
      "Non-trainable params: 3,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "d343720823fc37f33904cf3d9108b32748391a5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 176020 samples, validate on 44005 samples\n",
      "Epoch 1/10\n",
      "176020/176020 [==============================] - 335s 2ms/step - loss: 0.3570 - acc: 0.8478 - val_loss: 0.3337 - val_acc: 0.8572\n",
      "Epoch 2/10\n",
      "176020/176020 [==============================] - 331s 2ms/step - loss: 0.2586 - acc: 0.8968 - val_loss: 0.3200 - val_acc: 0.8662\n",
      "Epoch 3/10\n",
      " 47072/176020 [=======>......................] - ETA: 3:45 - loss: 0.2304 - acc: 0.9095"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,write_graph=True, write_images=False)\n",
    "# define model\n",
    "model.fit(X_train, y_train,\n",
    "          epochs=10,\n",
    "          validation_data=(X_test, y_test),\n",
    "          shuffle=True,\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "7d95ee82fe4c1a1bed18efd6feebad395bc8112c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: 0 - 5000\n",
      "5000/5000 [==============================] - 3s 611us/step\n",
      "Indexes: 5000 - 10000\n",
      "5000/5000 [==============================] - 3s 528us/step\n",
      "Indexes: 10000 - 15000\n",
      "5000/5000 [==============================] - 3s 525us/step\n",
      "Indexes: 15000 - 20000\n",
      "5000/5000 [==============================] - 3s 542us/step\n",
      "Indexes: 20000 - 25000\n",
      "5000/5000 [==============================] - 3s 527us/step\n",
      "Indexes: 25000 - 30000\n",
      "5000/5000 [==============================] - 3s 534us/step\n",
      "Indexes: 30000 - 35000\n",
      "5000/5000 [==============================] - 3s 530us/step\n",
      "Indexes: 35000 - 40000\n",
      "5000/5000 [==============================] - 3s 526us/step\n",
      "Indexes: 40000 - 45000\n",
      "5000/5000 [==============================] - 3s 526us/step\n",
      "Indexes: 45000 - 50000\n",
      "5000/5000 [==============================] - 3s 525us/step\n",
      "Indexes: 50000 - 55000\n",
      "5000/5000 [==============================] - 3s 529us/step\n",
      "Indexes: 55000 - 60000\n",
      "2458/2458 [==============================] - 1s 581us/step\n"
     ]
    }
   ],
   "source": [
    "base_test_dir = path + 'test/' #specify test data folder\n",
    "test_files = glob(os.path.join(base_test_dir,'*.tif')) #find the test file names\n",
    "submission = pd.DataFrame() #create a dataframe to hold results\n",
    "file_batch = 5000 #we will predict 5000 images at a time\n",
    "max_idx = len(test_files) #last index to use\n",
    "for idx in range(0, max_idx, file_batch): #iterate over test image batches\n",
    "    print(\"Indexes: %i - %i\"%(idx, idx+file_batch))\n",
    "    test_df = pd.DataFrame({'path': test_files[idx:idx+file_batch]}) #add the filenames to the dataframe\n",
    "    test_df['id'] = test_df.path.map(lambda x: x.split('/')[3].split(\".\")[0]) #add the ids to the dataframe\n",
    "    test_df['image'] = test_df['path'].map(cv2.imread) #read the batch\n",
    "    K_test = np.stack(test_df[\"image\"].values) #convert to numpy array\n",
    "    predictions = model.predict(K_test,verbose = 1) #predict the labels for the test data\n",
    "    test_df['label'] = predictions #store them in the dataframe\n",
    "    submission = pd.concat([submission, test_df[[\"id\", \"label\"]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "The code in the cell below is used to run tensorboard on kaggle<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "13f88fe276d640b58cf2b9373ed99258b1d6203d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-19 15:39:29--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\r\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 34.206.130.40, 52.55.191.55, 34.232.40.183, ...\r\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|34.206.130.40|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 14910739 (14M) [application/octet-stream]\r\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\r\n",
      "\r\n",
      "ngrok-stable-linux- 100%[===================>]  14.22M  41.4MB/s    in 0.3s    \r\n",
      "\r\n",
      "2019-03-19 15:39:30 (41.4 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [14910739/14910739]\r\n",
      "\r\n",
      "Archive:  ngrok-stable-linux-amd64.zip\r\n",
      "  inflating: ngrok                   \r\n",
      "https://6ad22fd5.ngrok.io\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "LOG_DIR = './logs' # Here you have to put your log directory\n",
    "get_ipython().system_raw(\n",
    "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "    .format(LOG_DIR)\n",
    ")\n",
    "get_ipython().system_raw('./ngrok http 6006 &')\n",
    "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Exporting the data as CSV<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "a44e106a23f662d5fa64ca88c7f65729fed50bb0"
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission.csv\", index = False, header = True) #create the submission file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
